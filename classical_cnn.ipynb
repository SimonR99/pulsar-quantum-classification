{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, recall_score, precision_score, confusion_matrix\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from utils import specificity_score, negative_prediction_value_score, gmean_score, informedness_score\n",
    "import torch.nn.functional as F\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from base_pulsa_ai import BasePulsarAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_pulsar_ai = BasePulsarAI()\n",
    "x_train, x_test, y_train, y_test = base_pulsar_ai.get_torch_htru_2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassicCNN(nn.Module):\n",
    "    def __init__(self, num_features, output_dim):\n",
    "        super(ClassicCNN, self).__init__()\n",
    "        self.conv1d = nn.Conv1d(in_channels=num_features, out_channels=128, kernel_size=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc1 = nn.Linear(128, 64)\n",
    "        self.fc2 = nn.Linear(64, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 8, 1)\n",
    "        x = self.conv1d(x)\n",
    "        x = self.relu(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "input_dim  = 8 # number of features\n",
    "output_dim = 2 # binary classification, to be change for sigmoid ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "ss = ShuffleSplit(n_splits=base_pulsar_ai.num_runs, train_size=60, test_size=120)\n",
    "\n",
    "def train_network(model,optimizer,criterion,x_train,y_train,x_test,y_test,num_epochs,train_losses,test_losses):\n",
    "    for epoch in range(num_epochs):\n",
    "        #clear out the gradients from the last step loss.backward()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        #forward feed\n",
    "        output_train = model(x_train)\n",
    "\n",
    "        #calculate the loss\n",
    "        loss_train = criterion(output_train, y_train)\n",
    "        \n",
    "        #backward propagation: calculate gradients\n",
    "        loss_train.backward()\n",
    "\n",
    "        #update the weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        output_test = model(x_test)\n",
    "        loss_test = criterion(output_test,y_test)\n",
    "\n",
    "        train_losses[epoch] = loss_train.item()\n",
    "        test_losses[epoch] = loss_test.item()\n",
    "\n",
    "for train_index, test_index in ss.split(x_train):\n",
    "    num_epochs = base_pulsar_ai.max_num_epochs\n",
    "    train_losses = np.zeros(num_epochs)\n",
    "    test_losses  = np.zeros(num_epochs)\n",
    "    model = ClassicCNN(input_dim, output_dim)\n",
    "\n",
    "    learning_rate = 0.01\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate)\n",
    "\n",
    "    train_network(model,optimizer,criterion, x_train,y_train, x_test,y_test,num_epochs,train_losses,test_losses)\n",
    "\n",
    "    # Predict the test set\n",
    "    output_test = model(x_test)\n",
    "    _, predicted_test = torch.max(output_test, 1)\n",
    "\n",
    "    # Calculate the scores\n",
    "    base_pulsar_ai.append_score(y_test, predicted_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.976 ± 0.000\n",
      "Balanced_accuracy: 0.904 ± 0.001\n",
      "Recall: 0.815 ± 0.002\n",
      "Specificity: 0.993 ± 0.000\n",
      "Precision: 0.924 ± 0.003\n",
      "Npv: 0.981 ± 0.000\n",
      "Gmean: 0.900 ± 0.001\n",
      "Informedness: 0.808 ± 0.003\n"
     ]
    }
   ],
   "source": [
    "# Print the scores\n",
    "for metric, values in base_pulsar_ai.scores.items():\n",
    "    mean_value = np.mean(values)\n",
    "    std_value = np.std(values)\n",
    "    print(f\"{metric.capitalize()}: {mean_value:.3f} ± {std_value:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quantum",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
