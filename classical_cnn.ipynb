{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Simon Roy\\AppData\\Local\\Temp\\ipykernel_25860\\3141778820.py:8: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, recall_score, precision_score, confusion_matrix\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from utils import specificity_score, negative_prediction_value_score, gmean_score, informedness_score\n",
    "import torch.nn.functional as F\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from base_pulsa_ai import BasePulsarAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_pulsar_ai = BasePulsarAI()\n",
    "x_train, x_test, y_train, y_test = base_pulsar_ai.get_torch_htru_2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4993, 0.5208, 0.5417,  ..., 0.5168, 0.5027, 0.5009],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "12527\n"
     ]
    }
   ],
   "source": [
    "class ClassicCNN(nn.Module):\n",
    "    def __init__(self, num_features, output_dim):\n",
    "        super(ClassicCNN, self).__init__()\n",
    "        self.conv1d = nn.Conv1d(in_channels=num_features, out_channels=128, kernel_size=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc1 = nn.Linear(128, 64)\n",
    "        self.fc2 = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 8, 1)\n",
    "        x = self.conv1d(x)\n",
    "        x = self.relu(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        x = torch.sigmoid(x)\n",
    "        x = x.squeeze(1)\n",
    "        return x\n",
    "\n",
    "\n",
    "input_dim  = 8 # number of features\n",
    "output_dim = 2 # binary classification, to be change for sigmoid ?\n",
    "\n",
    "model = ClassicCNN(input_dim, output_dim)\n",
    "output_train = model(x_train)\n",
    "\n",
    "print(output_train)\n",
    "print(len(output_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "ss = ShuffleSplit(n_splits=base_pulsar_ai.num_runs, train_size=60, test_size=120)\n",
    "\n",
    "def train_network(model,optimizer,criterion,x_train,y_train,x_test,y_test,num_epochs,train_losses,test_losses):\n",
    "    for epoch in range(num_epochs):\n",
    "        #clear out the gradients from the last step loss.backward()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        #forward feed\n",
    "        output_train = model(x_train.float())\n",
    "\n",
    "        #calculate the loss\n",
    "        loss_train = criterion(output_train, y_train.float())\n",
    "        \n",
    "        #backward propagation: calculate gradients\n",
    "        loss_train.backward()\n",
    "\n",
    "        #update the weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        output_test = model(x_test)\n",
    "        loss_test = criterion(output_test,y_test.float())\n",
    "\n",
    "        train_losses[epoch] = loss_train.item()\n",
    "        test_losses[epoch] = loss_test.item()\n",
    "\n",
    "for train_index, test_index in ss.split(x_train):\n",
    "    num_epochs = base_pulsar_ai.max_num_epochs\n",
    "    train_losses = np.zeros(num_epochs)\n",
    "    test_losses  = np.zeros(num_epochs)\n",
    "    model = ClassicCNN(input_dim, output_dim)\n",
    "\n",
    "    learning_rate = 0.01\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate)\n",
    "\n",
    "    train_network(model,optimizer,criterion, x_train,y_train, x_test,y_test,num_epochs,train_losses,test_losses)\n",
    "\n",
    "    # Predict the test set\n",
    "    output_test = model(x_test)\n",
    "    predicted_test = (output_test > 0.5).float()\n",
    "\n",
    "    # Calculate the scores\n",
    "    base_pulsar_ai.append_score(y_test, predicted_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.981 ± 0.000\n",
      "Balanced_accuracy: 0.932 ± 0.000\n",
      "Recall: 0.871 ± 0.001\n",
      "Specificity: 0.993 ± 0.000\n",
      "Precision: 0.926 ± 0.001\n",
      "Npv: 0.987 ± 0.000\n",
      "Gmean: 0.930 ± 0.000\n",
      "Informedness: 0.863 ± 0.001\n"
     ]
    }
   ],
   "source": [
    "# Print the scores\n",
    "for metric, values in base_pulsar_ai.scores.items():\n",
    "    mean_value = np.mean(values)\n",
    "    std_value = np.std(values)\n",
    "    print(f\"{metric.capitalize()}: {mean_value:.3f} ± {std_value:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quantum",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
