{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.979 ± 0.004\n",
      "Balanced_accuracy: 0.907 ± 0.022\n",
      "Recall: 0.820 ± 0.044\n",
      "Specificity: 0.995 ± 0.002\n",
      "Precision: 0.944 ± 0.025\n",
      "Npv: 0.982 ± 0.004\n",
      "Gmean: 0.903 ± 0.024\n",
      "Informedness: 0.815 ± 0.043\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, cross_validate, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, recall_score, precision_score, confusion_matrix, make_scorer\n",
    "from sklearn import svm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming you have your features as X and target variable as y from the dataset\n",
    "# Load the data\n",
    "df = pd.read_csv('./data/HTRU_2.csv', header=None)\n",
    "df.columns = ['IpMean', 'IpDev', 'IpKurt','IpSkew', 'DMMean', 'DMDev', 'DMKurt', 'DMSkew', 'Class']\n",
    "\n",
    "# Split the data into features and target\n",
    "X = df.iloc[:, :-1]\n",
    "y = df.iloc[:, -1]\n",
    "\n",
    "\n",
    "# Train = first 200 samples\n",
    "# Test = from 200 to 600\n",
    "\n",
    "X_train = X.iloc[:200, :]\n",
    "y_train = y.iloc[:200]\n",
    "\n",
    "X_test = X.iloc[200:600, :]\n",
    "y_test = y.iloc[200:600]\n",
    "\n",
    "\n",
    "# Initialize the model\n",
    "model = svm.SVC(kernel='linear', C=1.0)  # Adjust kernel and C as necessary\n",
    "\n",
    "# Define the cross-validation scheme\n",
    "cv = StratifiedKFold(n_splits=10)\n",
    "\n",
    "# Define custom scorers\n",
    "def specificity_score(y_true, y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    specificity = tn / (tn+fp)\n",
    "    return specificity\n",
    "\n",
    "def negative_prediction_value_score(y_true, y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    npv = tn / (tn+fn)\n",
    "    return npv\n",
    "\n",
    "def gmean_score(y_true, y_pred):\n",
    "    rec = recall_score(y_true, y_pred)\n",
    "    spec = specificity_score(y_true, y_pred)\n",
    "    return np.sqrt(rec * spec)\n",
    "\n",
    "def informedness_score(y_true, y_pred):\n",
    "    rec = recall_score(y_true, y_pred)\n",
    "    spec = specificity_score(y_true, y_pred)\n",
    "    return rec + spec - 1\n",
    "\n",
    "# Create a dictionary of scorers\n",
    "scorers = {\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'balanced_accuracy': make_scorer(balanced_accuracy_score),\n",
    "    'recall': make_scorer(recall_score),\n",
    "    'specificity': make_scorer(specificity_score),\n",
    "    'precision': make_scorer(precision_score),\n",
    "    'npv': make_scorer(negative_prediction_value_score),\n",
    "    'gmean': make_scorer(gmean_score),\n",
    "    'informedness': make_scorer(informedness_score)\n",
    "}\n",
    "\n",
    "# Perform cross-validation and collect metrics\n",
    "scores = cross_validate(model, X, y, scoring=scorers, cv=cv, return_train_score=False)\n",
    "\n",
    "# Calculate mean and standard deviation for each metric\n",
    "results = {metric: {\"mean\": np.mean(scores['test_'+metric]), \"std\": np.std(scores['test_'+metric])} for metric in scorers}\n",
    "\n",
    "# Display the results\n",
    "for metric, value in results.items():\n",
    "    print(f\"{metric.capitalize()}: {value['mean']:.3f} ± {value['std']:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IpMean</th>\n",
       "      <th>IpDev</th>\n",
       "      <th>IpKurt</th>\n",
       "      <th>IpSkew</th>\n",
       "      <th>DMMean</th>\n",
       "      <th>DMDev</th>\n",
       "      <th>DMKurt</th>\n",
       "      <th>DMSkew</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>140.562500</td>\n",
       "      <td>55.683782</td>\n",
       "      <td>-0.234571</td>\n",
       "      <td>-0.699648</td>\n",
       "      <td>3.199833</td>\n",
       "      <td>19.110426</td>\n",
       "      <td>7.975532</td>\n",
       "      <td>74.242225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102.507812</td>\n",
       "      <td>58.882430</td>\n",
       "      <td>0.465318</td>\n",
       "      <td>-0.515088</td>\n",
       "      <td>1.677258</td>\n",
       "      <td>14.860146</td>\n",
       "      <td>10.576487</td>\n",
       "      <td>127.393580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103.015625</td>\n",
       "      <td>39.341649</td>\n",
       "      <td>0.323328</td>\n",
       "      <td>1.051164</td>\n",
       "      <td>3.121237</td>\n",
       "      <td>21.744669</td>\n",
       "      <td>7.735822</td>\n",
       "      <td>63.171909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>136.750000</td>\n",
       "      <td>57.178449</td>\n",
       "      <td>-0.068415</td>\n",
       "      <td>-0.636238</td>\n",
       "      <td>3.642977</td>\n",
       "      <td>20.959280</td>\n",
       "      <td>6.896499</td>\n",
       "      <td>53.593661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>88.726562</td>\n",
       "      <td>40.672225</td>\n",
       "      <td>0.600866</td>\n",
       "      <td>1.123492</td>\n",
       "      <td>1.178930</td>\n",
       "      <td>11.468720</td>\n",
       "      <td>14.269573</td>\n",
       "      <td>252.567306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17893</th>\n",
       "      <td>136.429688</td>\n",
       "      <td>59.847421</td>\n",
       "      <td>-0.187846</td>\n",
       "      <td>-0.738123</td>\n",
       "      <td>1.296823</td>\n",
       "      <td>12.166062</td>\n",
       "      <td>15.450260</td>\n",
       "      <td>285.931022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17894</th>\n",
       "      <td>122.554688</td>\n",
       "      <td>49.485605</td>\n",
       "      <td>0.127978</td>\n",
       "      <td>0.323061</td>\n",
       "      <td>16.409699</td>\n",
       "      <td>44.626893</td>\n",
       "      <td>2.945244</td>\n",
       "      <td>8.297092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17895</th>\n",
       "      <td>119.335938</td>\n",
       "      <td>59.935939</td>\n",
       "      <td>0.159363</td>\n",
       "      <td>-0.743025</td>\n",
       "      <td>21.430602</td>\n",
       "      <td>58.872000</td>\n",
       "      <td>2.499517</td>\n",
       "      <td>4.595173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17896</th>\n",
       "      <td>114.507812</td>\n",
       "      <td>53.902400</td>\n",
       "      <td>0.201161</td>\n",
       "      <td>-0.024789</td>\n",
       "      <td>1.946488</td>\n",
       "      <td>13.381731</td>\n",
       "      <td>10.007967</td>\n",
       "      <td>134.238910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17897</th>\n",
       "      <td>57.062500</td>\n",
       "      <td>85.797340</td>\n",
       "      <td>1.406391</td>\n",
       "      <td>0.089520</td>\n",
       "      <td>188.306020</td>\n",
       "      <td>64.712562</td>\n",
       "      <td>-1.597527</td>\n",
       "      <td>1.429475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17898 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           IpMean      IpDev    IpKurt    IpSkew      DMMean      DMDev  \\\n",
       "0      140.562500  55.683782 -0.234571 -0.699648    3.199833  19.110426   \n",
       "1      102.507812  58.882430  0.465318 -0.515088    1.677258  14.860146   \n",
       "2      103.015625  39.341649  0.323328  1.051164    3.121237  21.744669   \n",
       "3      136.750000  57.178449 -0.068415 -0.636238    3.642977  20.959280   \n",
       "4       88.726562  40.672225  0.600866  1.123492    1.178930  11.468720   \n",
       "...           ...        ...       ...       ...         ...        ...   \n",
       "17893  136.429688  59.847421 -0.187846 -0.738123    1.296823  12.166062   \n",
       "17894  122.554688  49.485605  0.127978  0.323061   16.409699  44.626893   \n",
       "17895  119.335938  59.935939  0.159363 -0.743025   21.430602  58.872000   \n",
       "17896  114.507812  53.902400  0.201161 -0.024789    1.946488  13.381731   \n",
       "17897   57.062500  85.797340  1.406391  0.089520  188.306020  64.712562   \n",
       "\n",
       "          DMKurt      DMSkew  \n",
       "0       7.975532   74.242225  \n",
       "1      10.576487  127.393580  \n",
       "2       7.735822   63.171909  \n",
       "3       6.896499   53.593661  \n",
       "4      14.269573  252.567306  \n",
       "...          ...         ...  \n",
       "17893  15.450260  285.931022  \n",
       "17894   2.945244    8.297092  \n",
       "17895   2.499517    4.595173  \n",
       "17896  10.007967  134.238910  \n",
       "17897  -1.597527    1.429475  \n",
       "\n",
       "[17898 rows x 8 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\simon\\.conda\\envs\\quantum\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\simon\\.conda\\envs\\quantum\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\simon\\.conda\\envs\\quantum\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\simon\\.conda\\envs\\quantum\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.970 ± 0.033\n",
      "Balanced_accuracy: 0.747 ± 0.253\n",
      "Recall: 0.500 ± 0.500\n",
      "Specificity: 0.995 ± 0.016\n",
      "Precision: 0.500 ± 0.500\n",
      "Npv: 0.975 ± 0.025\n",
      "Gmean: 0.500 ± 0.500\n",
      "Informedness: 0.495 ± 0.505\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, cross_validate, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, recall_score, precision_score, confusion_matrix, make_scorer\n",
    "from sklearn import svm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming you have your features as X and target variable as y from the dataset\n",
    "# Load the data\n",
    "df = pd.read_csv('./data/HTRU_2.csv', header=None)\n",
    "df.columns = ['IpMean', 'IpDev', 'IpKurt','IpSkew', 'DMMean', 'DMDev', 'DMKurt', 'DMSkew', 'Class']\n",
    "\n",
    "# Split the data into features and target\n",
    "X = df.iloc[:, :-1]\n",
    "y = df.iloc[:, -1]\n",
    "\n",
    "# Train = first 200 samples\n",
    "# Test = from 200 to 600\n",
    "\n",
    "X_train = X.iloc[:200, :]\n",
    "y_train = y.iloc[:200]\n",
    "\n",
    "X_test = X.iloc[200:600, :]\n",
    "y_test = y.iloc[200:600]\n",
    "\n",
    "# Initialize the model\n",
    "model = svm.SVC(kernel='linear', C=1.0)  # Adjust kernel and C as necessary\n",
    "\n",
    "# Define the cross-validation scheme\n",
    "cv = StratifiedKFold(n_splits=10)\n",
    "\n",
    "# Define custom scorers\n",
    "def specificity_score(y_true, y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    specificity = tn / (tn+fp)\n",
    "    return specificity\n",
    "\n",
    "def negative_prediction_value_score(y_true, y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    npv = tn / (tn+fn)\n",
    "    return npv\n",
    "\n",
    "def gmean_score(y_true, y_pred):\n",
    "    rec = recall_score(y_true, y_pred)\n",
    "    spec = specificity_score(y_true, y_pred)\n",
    "    return np.sqrt(rec * spec)\n",
    "\n",
    "def informedness_score(y_true, y_pred):\n",
    "    rec = recall_score(y_true, y_pred)\n",
    "    spec = specificity_score(y_true, y_pred)\n",
    "    return rec + spec - 1\n",
    "\n",
    "# Create a dictionary of scorers\n",
    "scorers = {\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'balanced_accuracy': make_scorer(balanced_accuracy_score),\n",
    "    'recall': make_scorer(recall_score),\n",
    "    'specificity': make_scorer(specificity_score),\n",
    "    'precision': make_scorer(precision_score),\n",
    "    'npv': make_scorer(negative_prediction_value_score),\n",
    "    'gmean': make_scorer(gmean_score),\n",
    "    'informedness': make_scorer(informedness_score)\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform cross-validation and collect metrics\n",
    "scores = cross_validate(model, X_train, y_train, scoring=scorers, cv=cv, return_train_score=False)\n",
    "\n",
    "# Calculate mean and standard deviation for each metric\n",
    "results = {metric: {\"mean\": np.mean(scores['test_'+metric]), \"std\": np.std(scores['test_'+metric])} for metric in scorers}\n",
    "\n",
    "# Display the results\n",
    "for metric, value in results.items():\n",
    "    print(f\"{metric.capitalize()}: {value['mean']:.3f} ± {value['std']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.968\n",
      "Balanced accuracy: 0.887\n",
      "Recall: 0.780\n",
      "Precision: 0.951\n",
      "Confusion matrix:\n",
      "[[348   2]\n",
      " [ 11  39]]\n",
      "Specificity: 0.994\n",
      "NPV: 0.969\n",
      "G-Mean: 0.881\n"
     ]
    }
   ],
   "source": [
    "# test the model\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate the metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "balanced_accuracy = balanced_accuracy_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Display the results\n",
    "print(f\"Accuracy: {accuracy:.3f}\")\n",
    "print(f\"Balanced accuracy: {balanced_accuracy:.3f}\")\n",
    "print(f\"Recall: {recall:.3f}\")\n",
    "print(f\"Precision: {precision:.3f}\")\n",
    "print(f\"Confusion matrix:\\n{conf_matrix}\")\n",
    "print(f\"Specificity: {specificity_score(y_test, y_pred):.3f}\")\n",
    "print(f\"NPV: {negative_prediction_value_score(y_test, y_pred):.3f}\")\n",
    "print(f\"G-Mean: {gmean_score(y_test, y_pred):.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quantum",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
